# -*- coding: utf-8 -*-
"""submission_dicoding_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OLP1KuLckNAyBAxUcWtMXSSh3ZPa6B7a

**Submission Dicoding Belajar Machine Learning Untuk Pemula**

Nama : Didik Kurniawan

Username Dicoding : didik_kurniawan_slVA

Email : didik2584@gmail.com

**1.  Import Library TensorFlow, Keras dan Masukkan Dataset**
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D

tf.__version__

!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

"""
**2.   Setup dan Import Library**

"""

!pip install split_folders

# Commented out IPython magic to ensure Python compatibility.
import zipfile,os
import splitfolders
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
import numpy as np
from google.colab import files
from keras.preprocessing import image

"""**3. Memisahkan Data Train dan Validasi**"""

local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('rps')
zip_ref.close()

splitfolders.ratio('rps/rockpaperscissors/rps-cv-images', output="rps/rockpaperscissors/data", seed=1337, ratio=(.6, .4))

data_dir = 'rps/rockpaperscissors/data'
train_dir = os.path.join(data_dir, 'train')
validation_dir = os.path.join(data_dir, 'val')

print(len(os.listdir('rps/rockpaperscissors/rock')))
print(len(os.listdir('rps/rockpaperscissors/paper')))
print(len(os.listdir('rps/rockpaperscissors/scissors')))

train_rock_dir = os.path.join(train_dir, 'rock')
train_paper_dir = os.path.join(train_dir, 'paper')
train_scissors_dir = os.path.join(train_dir, 'scissors')

validation_rock_dir = os.path.join(validation_dir, 'rock')
validation_paper_dir = os.path.join(validation_dir, 'paper')
validation_scissors_dir = os.path.join(validation_dir, 'scissors')

rock_imgs = os.listdir(train_rock_dir)
paper_imgs = os.listdir(train_paper_dir)
scissors_imgs = os.listdir(train_scissors_dir)

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(rock_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_rock_dir, img_path))
  plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(paper_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_paper_dir, img_path))
  plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(scissors_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_scissors_dir, img_path))
  plt.imshow(img)
plt.show()

"""**4. Augmentasi Gambar**"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.9999,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

validation_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.9999
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (100, 100),
    batch_size = 32,
    class_mode = 'categorical',
    shuffle = True
)

valid_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size = (100, 100),
    batch_size = 32,
    class_mode = 'categorical',
    shuffle = True,
)

train_generator.class_indices

valid_generator.class_indices

"""**5. Melatih sebuah model Convolutional Neural Network**"""

model = Sequential()

model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.summary()

"""**6. Kompilasi Model & Alur Pelatihan**"""

model.compile(
    optimizer = 'RMSprop',
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

history = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=20,
    validation_data=valid_generator,
    validation_steps=5,
    verbose=2
)

"""**7. Evaluasi Model**"""

score = model.evaluate(train_generator)

print('Loss:', round(score[0] * 100, 2), '%')
print('Accuracy:', round(score[1] * 100, 2), '%')

score = model.evaluate(valid_generator)

print('Loss:', round(score[0] * 100, 2), '%')
print('Accuracy:', round(score[1] * 100, 2), '%')

tf.saved_model.save(model, "RPS_SAVED_MODEL")

"""**8. Plot Kurva Data Latih dan Validasi**"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(acc, color='orange')
plt.plot(val_acc, color='green')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc='upper right')

plt.subplot(1, 2, 2)
plt.plot(loss, color='orange')
plt.plot(val_loss, color='green')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Valid'], loc='upper right')
plt.show()

"""**9. Memprediksi Model Data yang ada dengan Upload Gambar**"""

uploaded = files.upload()

for fn in uploaded.keys():


  path = fn
  img = tf.keras.utils.load_img(path, target_size=(100,100))
  imgplot = plt.imshow(img)
  x = tf.keras.utils.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  print(fn)
  if classes[0,0] == 1.0:
    print('Paper')
  elif classes[0,1] == 1.0:
    print('Rock')
  else:
    print('Scissors')